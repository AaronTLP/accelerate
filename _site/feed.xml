<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/feed.xml" rel="self" type="application/atom+xml" /><link href="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/" rel="alternate" type="text/html" /><updated>2022-10-14T14:19:12+01:00</updated><id>https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/feed.xml</id><title type="html">Accelerate Programme</title><subtitle>Advancing scientific discovery with machine learning.</subtitle><entry><title type="html">How can we…use AI to understand acute respiratory distress syndrome?</title><link href="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/2022/05/17/how-can-we-use-ai-to-understand-acute-respiratory-distress-syndrome.html" rel="alternate" type="text/html" title="How can we…use AI to understand acute respiratory distress syndrome?" /><published>2022-05-17T00:00:00+01:00</published><updated>2022-05-17T00:00:00+01:00</updated><id>https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/2022/05/17/how-can-we-use-ai-to-understand-acute-respiratory-distress-syndrome</id><content type="html" xml:base="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/2022/05/17/how-can-we-use-ai-to-understand-acute-respiratory-distress-syndrome.html"><![CDATA[<p>Acute respiratory distress syndrome (ARDS) affects one in 10 critical care patients. It is a condition in which the lungs cannot provide the body’s vital organs with enough oxygen; it is often a complication of a serious illness or infection and is fairly common, but under recognised.</p>

<p>Mortality from severe ARDS is approximately 40%. So, when treating these patients, you would see just over half of them get better. Some may be talking to you one day before needing a ventilator the next, and sadly dying a few days later, despite your best efforts. Doctors saw more people suffering from ARDS as a result of COVID-19 infection, and often it seemed like, as a doctor, everything you tried did nothing.</p>

<p>We have seen incredible advances in other medical fields over 50 years, but the percentage of people dying from ARDS has not changed and it remains the biggest problem in intensive care medicine. Treatments have been developed that work in a petri dish and in animals, but we can’t get them to work in humans because we simply don’t understand the relevant biology.</p>

<p>I decided to become a clinical academic trainee because I was frustrated by repeated failures of promising treatments for critically unwell patients in clinical trials. I’m using machine learning techniques to tap into the wealth of data from different studies and explain the underlying biological processes in groups of patients, which are currently poorly understood, resulting in failure to find new treatments.</p>

<p><strong>Using data to solve a deadly problem</strong></p>

<p>As a clinical academic I work clinical shifts but have the ‘brain-space’ to teach and use new research methods, techniques and tools. One area of interest has been machine learning and how to program, using Python, which I learned on the Accelerate Programme for Scientific Discovery mid-way through my PhD. </p>

<p>Learning Python has enabled me to analyse a vast amount of data from ARDS and sepsis studies in the UK, as well as randomised control trials, using data science techniques to identify different subgroups of patients and understand how their biology relates to disease progression. I sort datasets into a network or topology and then look at how different features of patients change in that network to see if there are any distinctive subtypes, or endotypes. If I find these, I’m able to look at biological differences between them and then use other types of data to corroborate my findings. </p>

<p>Using machine learning has led to insights into patient outcomes, and some of them are quite unexpected. My thesis attempted to address heterogeneity and explored the underlying biology by using an integrated, unsupervised bioinformatics approach to describe different mechanistic subtypes, or endotypes, of ARDS.</p>

<p>These endotypes were derived from analysis of data collected by three UK-based studies. I used a combination of automated clustering methods and network analysis tools to integrate blood biomarkers and gene expression data and define distinct endotypes of ARDS.</p>

<p>In patients with influenza, we found that for some patients ARDS was characterised by processes associated with leaky blood vessels in the their lungs, whilst others showed activation of different parts of the immune system. What surprised us was how patients who appeared critically unwell and needed a ventilator had different outcomes if they were associated with different endotypes.</p>

<p>Identifying the biological reasons why some patient groups that do well and some do not is important, as it could allow doctors to give targeted drugs to patients that have everything to gain from a particular intervention, while avoiding using them for patients whom they might make sicker. It could also lead to drugs that target specific biological mechanisms. While this is a long way from being validated, seeing that such personalised medicine may be on the horizon is exciting.</p>

<p><strong>Putting research into practice</strong> </p>

<p>Machine learning is undoubtedly revolutionising healthcare, but there are several challenges to overcome. One is them is that intensive care data can be difficult for programs to interpret. Despite being rich in information, healthcare records are often full of shorthand expressions, acronyms and annotations, which doctors and nurses can easily decode and explain, but when read by machine learning programs, the data can be misinterpreted. Because of this, the records are not necessarily a good substrate for machines to understand a patient’s condition or why decisions have been made. Currently, the only way of overcoming this problem, is to manually visualise and check the data.</p>

<p>Even with this manual process, it is hard to rely on clinical datasets as test results, for example, they do not explain why patients become sick in the first place. It is also hard to place trust in machine learning algorithms that have been trained on extensively curated and cleaned data but not in a live healthcare setting where there is so much at stake. </p>

<p><strong>The ultimate aim</strong></p>

<p>The goal of understanding how to treat patients with ARDS gained a new level of urgency with the arrival of COVID-19, when the public became aware of thousands of patients dying on ventilators. </p>

<p>My research in ARDS continues and now also incorporates COVID, so I’m applying what I’ve found to COVID datasets. The pandemic has certainly sparked more interest in ARDS both in the UK and across the world and public datasets generated during this time will be an ongoing resource and ultimately benefit patients with and without COVID-19.</p>

<p>The ultimate goal is phenotyping – working out the exact underlying physical processes and biology of patients – so that intensive care clinicians will be able to work out the best trajectory for individuals based on features detected from simple blood tests that could measure genes or proteins in the blood.</p>

<p>While this may be around 20 years away, my research is part of a growing body of work that will help doctors treat ARDS more effectively, and hopefully end 50 years of limited progress in this area of intensive care medicine.</p>

<p><strong><em>Dr Romit Samanta, NIHR Clinical Lecturer in Intensive Care Medicine, University of Cambridge (May 2022)</em></strong></p>]]></content><author><name>Dr Romit Samanta, NIHR Clinical Lecturer in Intensive Care Medicine, University of Cambridge</name></author><summary type="html"><![CDATA[Acute respiratory distress syndrome (ARDS) affects one in 10 critical care patients. It is a condition in which the lungs cannot provide the body’s vital organs with enough oxygen, often as a result of infection. It is fairly common, but under-recognised and difficult to treat, partly due a lack of understanding of the underlying biology. Could machine learning help us identify more effective treatments for patients with ARDS?]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/assets/uploads/romit-headshot.jpg" /><media:content medium="image" url="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/assets/uploads/romit-headshot.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">How can we…use AI to take bio-imaging to the next dimension?</title><link href="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/accelerate-spark%20data%20science%20residency/2022/03/23/daniel-esteban-ferrer-ai-for-bioimaging.html" rel="alternate" type="text/html" title="How can we…use AI to take bio-imaging to the next dimension?" /><published>2022-03-23T16:49:00+00:00</published><updated>2022-03-23T16:49:00+00:00</updated><id>https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/accelerate-spark%20data%20science%20residency/2022/03/23/daniel-esteban-ferrer-ai-for-bioimaging</id><content type="html" xml:base="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/accelerate-spark%20data%20science%20residency/2022/03/23/daniel-esteban-ferrer-ai-for-bioimaging.html"><![CDATA[<p>Super-resolution microscopy makes it possible to obtain images at the nanoscale by using clever tricks of physics to get around the limits imposed by light diffraction. This innovation, which was awarded the <a href="https://www.nobelprize.org/prizes/chemistry/2014/summary/">Nobel Prize for Chemistry in 2014</a>, has allowed researchers to observe molecular processes as they happen. However, the data generated by this tool is huge, and there has been a lack of ways to visualise and analyse it in three dimensions.</p>

<p><strong>Addressing the bio imaging challenge</strong></p>

<p>My research at Cambridge focused on producing tools to allow the effective use and visualisation of three-dimensional datasets, including using virtual reality systems to visualise super-resolution microscopy images. There are many applications of this research, from drug discovery and diagnosis applications in life sciences, to materials research and engineering developments.</p>

<p>I helped create software called <a href="https://www.nature.com/articles/s41592-020-0962-1">vLUME</a> that allows super-resolution microscopy data to be visualised and analysed in virtual reality, so that researchers can ‘walk inside’ their data and examine everything from individual proteins to entire cells. This allows them to interact with data in an intuitive and immersive way, and potentially find answers to biological questions faster.</p>

<p>The software allows multiple datasets with millions of data points to be inputted and finds patterns in the complex data using in-built clustering algorithms. These findings can then be shared with collaborators worldwide using image and video features in the software.</p>

<p><strong>A new start(up)</strong></p>

<p>Having finished this research at the University of Cambridge, I created a company with the idea of working out new ways of visualizing and analysing 3D biomedical data. In 2020 <a href="https://vri.cat">VRi</a> was born and I am focusing my efforts on it as CEO. However, I will still work with the Chemistry department, providing them with our imaging software in return for data and feedback.</p>

<p>VRi’s software can be used in virtual reality, but it also allows researchers to work with and visualise huge amounts of data from imaging technologies –  Advanced Light Microscopy, Magnetic Resonance Imaging (MRI), (Micro) Computerized Tomography (CT), Atomic Force Microscopy, and (Cryo) Electron Microscopy – more intuitively. We’re basically developing the X-rays of the 21st century. We can digest any kind of data file (DICOM, Tiff-stacks, NIfTI, etc.), any type of medical imaging instruments data (MRI, CT, ultrasound, etc., regardless of the brand) and any scale of this data, from nano (subcellular) to macro (full body).</p>

<p>One of our first products, driven by the need of some pharma companies that we contacted, was an automatic Brain Atlas mapper. Many analyses of 3D bioimages rely on highly qualified individuals to map an atlas of scans into the organ - moving from 2d to 3d - taking approximately four minutes per slice. However, we use deep learning neural networks to automatically map them 1,000 times faster, saving pharmaceutical companies, hospitals and research institutes weeks of work. We use Python, Tensor flow and many other libraries to create a deformation matrix that matches our brain with a reference brain and then invert it to segment our original data using the reference Atlas.</p>

<p>Alzheimer lesion quantification is another application of the technology. With our platform we are able to use scans to segment and quantify brain changes arising from a number of diseases, including dementia and other neurodegenerative diseases such as Multiple Sclerosis. Give us a large number of datasets and we will do it!</p>

<p>I was keen to learn Python as part of the Accelerate Programme for Scientific Discovery while I was a researcher mulling over how to commercialise my research. While I don’t need to use the software while heading up VRi, because we have two dedicated data scientist and machine learning experts on my team, the knowledge I gained from the course is still incredibly useful. It would be harder to understand how they are using machine learning or speak the same language as technical team members, without the information I learned on the programme. Maybe I could have reached where I am today without it, but it would probably have taken longer.</p>

<p><strong>Looking to the future</strong></p>

<p>For now, our technology is largely used by researchers for blue sky science, but we plan to start working on real use cases that will more directly benefit society. One application we’re developing is the automatic measurement of the different magnitudes of blood vessels, which could help doctors prepare faster for vascular surgery. This is still work in progress but it could save at least one to two hours of tedious, repetitive work for vascular surgeons every day. We plan to have our first commercial application (for research use only) in less than one year. We hope to obtain CE and FDA certifications within the next two years, which would unlock the market to international healthcare systems. And finally, we are looking for external funding, a Chief Medical Officer, and we are always open to hire the best talent in Data Science,  Machine Learning for bioimaging and Computer Vision.</p>

<p><strong><em>Daniel Esteban-Ferrer (March 2022)</em></strong></p>]]></content><author><name>Daniel Esteban-Ferrer, CEO, VRi</name></author><category term="Accelerate-Spark data science residency" /><category term="news" /><summary type="html"><![CDATA[Huge amounts of data are generated by modern microscopy and imaging studies. Our work helps researchers make sense of this data by visualising datasets in intuitive and immersive formats. This has applications across a range of domains, and our current work is investigating how doctors can make use of new software to analyse brain scans and prepare for surgeries.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/%5B%22/assets/uploads/ct-scan.jpg%22%5D" /><media:content medium="image" url="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/%5B%22/assets/uploads/ct-scan.jpg%22%5D" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">How can we… Use AI to enable doctors to build their own models with clinical data?</title><link href="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/accelerate-spark%20data%20science%20residency/2022/02/01/enabling-doctors-to-build-their-own-models.html" rel="alternate" type="text/html" title="How can we… Use AI to enable doctors to build their own models with clinical data?" /><published>2022-02-01T10:00:00+00:00</published><updated>2022-02-01T10:00:00+00:00</updated><id>https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/accelerate-spark%20data%20science%20residency/2022/02/01/enabling-doctors-to-build-their-own-models</id><content type="html" xml:base="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/accelerate-spark%20data%20science%20residency/2022/02/01/enabling-doctors-to-build-their-own-models.html"><![CDATA[<p>Significant postoperative bleeding is a common and sometimes fatal complication of heart surgery. Deciding which treatment is needed to stop the bleeding is difficult, as there are several factors that influence why bleeding occurs, including characteristics specific to the individual patient, interventions that are taken to prepare the patient for surgery, the type of surgery, and how the various interventions in the operating room have gone. There are 12 different clotting factors in the blood that all influence each other and need to be at the correct levels to make the chemical reactions that allow the blood to clot. This ‘coagulation cascade’ means that the choice of which blood product to transfuse is a difficult one, which involves many different tests and specialist clinicians. If a patient is bleeding profusely, it could be that they need more stitches, or it might mean that the components of the blood are not at the right levels to form a clot. Consequently, there are two main types of interventions to stop postoperative bleeding: further surgery, or transfusion which can include blood products or coagulant medications.</p>

<p>Whether to intervene with medications, transfusions, or surgery is just one of many critical decisions made by teams of different specialists caring for a patient, who draw upon observations, specialised information and their own experience.</p>

<p>Each of these interventions comes with trade-offs and risks to the patient, such as infection, and considerations at an institutional level, such as blood inventory management and use of theatre time and space, plus the consequences for delaying other patients. These risks and trade-offs are managed by a team of clinicians from different specialities who observe the patient with different frequencies and incorporate specific data and tests. To make the best decision for the patient, the process must involve coming to agreement and incorporating as much of the available data as possible within tight timeframes.</p>

<p><strong>Collecting and Analysing Data from the Clinical Context</strong></p>

<p>My research focuses on helping clinicians make data-driven decisions around postoperative bleeding by harnessing the power of artificial intelligence. As a human-computer interaction researcher, my work started with a field study of postoperative bleeding decisions in context at a specialist heart and lung hospital in Cambridge and involved remote interviews and targeted observations in the ICU (working around the constraints of the covid pandemic).</p>

<p>After completing this initial fieldwork and acquiring a dataset containing 20000 patient observations, I attended the <a href="https://www.cst.cam.ac.uk/news/free-data-science-training-course-cambridge-researchers">Accelerate-Spark Data for Science Residency Programme</a>, which helped me get to grips with practical data science processes like data cleaning. I had no previous experience with this, but it is essential for getting data into a usable format in order to visualise, analyse and start to build AI models.</p>

<p>The instructors on the course did lots of live coding of examples of data cleaning tasks, visualisation, and analysis, which was invaluable because it taught me a real time data science workflow, which involves looking up information on Stack Overflow, for example. Learning how to search for new functions and fix errors in the code was empowering as it gave me the tools to explore and experiment on my own. The programme also opened up new possibilities to me for how to visualise data and taught me to use tools like Jupyter Notebook, which enabled me to annotate my code to communicate analysis to my advisers and collaborate with them easily.</p>

<p>Now I am working on identifying which variables or combinations of variables (such as amount of bleeding at different timescales or type of surgery or patient characteristics like age or BMI) are predictive of a patient needing to be returned to theatre for further surgery, so I can build a probabilistic model using these features. A probabilistic machine learning approach allows for incorporation of uncertainty estimates in decisions which is the focus of my work.</p>

<p><strong>Leveraging Past Cases and Visualising Uncertainty</strong></p>

<p>My goal is to create modelling tools that clinicians can use, but the probabilistic programming languages that I am going to be using in my research are often unintuitive to non-statisticians. The next challenge will be to build an intuitive interface to help them visualise and reason with the uncertainty around sending a patient back to theatre and do scenario analysis on possible interventions.</p>

<p>As an endpoint, I envisage the tool being used at the bedside on a hospital computer, so it could be used as a convening tool by specialists. For example, it could prove helpful to discuss risks and priorities as well as explore possible trajectories for a patient during a multidisciplinary team meeting. In my PhD work, I will not be deploying this tool in realtime but will be experimenting with it in a controlled setting by asking clinicians to work through case studies with the assistance of the tool and provide feedback on the design and use.</p>

<p>Having the full institutional history of patient data to draw upon in decision making is one advantage of AI that clinicians are keen to embrace. I hope that the final iteration of the tool will not only give clinicians access to a wealth of case histories, but make it possible for them to create their own models of the data by putting together their assumptions and then running the inference to see the consequences for an individual patient trajectory.</p>

<p>Making a decision harnessing all of the data available could help find patterns that could not be seen by an individual clinician or a set of clinicians just drawing on their own experience. The goal is to empower clinical domain experts with tools from statistics and computer science in order for them to get the most out of their data at the bedside and make the best possible decisions.</p>

<p><strong><em>Diana Robinson (February 2022)</em></strong></p>]]></content><author><name>Diana Robinson, University of Cambridge</name></author><category term="Accelerate-Spark data science residency" /><category term="news" /><summary type="html"><![CDATA[Having the full institutional history of patient data to draw upon in decision making is one advantage of AI that clinicians are keen to embrace. AI-enabled data analysis could help clinicians pursue more effective treatments for issues such as post-operative bleeding, but AI tools will need to be fit for clinical practice.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/%5B%22/assets/uploads/dianarobinson.jpg%22%5D" /><media:content medium="image" url="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/%5B%22/assets/uploads/dianarobinson.jpg%22%5D" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">The frontiers, opportunities and challenges of AI for science – Accelerate’s 2021 Symposium</title><link href="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/accelerate-spark%20data%20science%20residency/2021/12/22/Accelerate-annual-symposium.html" rel="alternate" type="text/html" title="The frontiers, opportunities and challenges of AI for science – Accelerate’s 2021 Symposium" /><published>2021-12-22T10:00:00+00:00</published><updated>2021-12-22T10:00:00+00:00</updated><id>https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/accelerate-spark%20data%20science%20residency/2021/12/22/Accelerate-annual-symposium</id><content type="html" xml:base="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/accelerate-spark%20data%20science%20residency/2021/12/22/Accelerate-annual-symposium.html"><![CDATA[<p><em>On 19 November, Accelerate brought together researchers from across Cambridge to share perspectives on how AI is supporting their work. This post summarises some of the key points from discussions.</em></p>

<p>Researchers today have access to more and larger datasets than ever before. This data comes from large-scale scientific studies, from the digital mediation of daily activities, and from new approaches to simulation that generate synthetic datasets. Amidst this sea of data, the challenge is to make these vast datasets <a href="http://inverseprobability.com/publications/data-readiness-levels.html">‘drinkable’</a>. To make this data manageable, researchers need new tools that can interrogate a greater range of data types from a wider range of data sources, extracting insights in support of scientific progress.</p>

<p>In this context, there has been great enthusiasm for the use of machine learning and artificial intelligence as enablers of scientific discovery. These methods are already being deployed in the service of science – on this blog, we’ve featured posts about their use in <a href="https://acceleratescience.github.io/2021/06/24/NicolaMoloney-ML-for-parasitology">cell biology</a>, <a href="https://acceleratescience.github.io/2021/07/08/Andreas-Schachner-ML-for-string-theory">physics</a>, and <a href="https://acceleratescience.github.io/2021/09/22/Emanuele-Osimo-ML-for-understanding-schizophrenia">genetics</a> – and high-profile AI-enabled discoveries have generated excitement about the future of AI for science. At the same time, we’ve seen a range of ways in which AI can fail in deployment: whether in producing <a href="https://www.technologyreview.com/2021/07/30/1030329/machine-learning-ai-failed-covid-hospital-diagnosis-pandemic/">health diagnostic tools that fail in clinical settings</a>; <a href="https://docs.google.com/presentation/d/1ueNmKvirobYVjZ5u9Lf3sawL8TeT3FZErZZfNMWsI_g/edit#slide=id.ge040bc5ade_0_25">introducing biases</a> into datasets that can skew scientific interpretations; or through their <a href="https://spectrum.ieee.org/ai-failures">‘brittleness’</a> in deployment. AI can be a powerful analytical tool, but making effective use of it requires careful examination of the challenge at hand and the context in which it will be deployed, which in turn requires expertise from different domains.</p>

<p>One of the highest profile successes in the use of AI for science in the last year has come from <a href="https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology">DeepMind’s AlphaFold project</a>, which uses AI to advance scientific understandings of protein folding. In a fireside chat with Neil Lawrence, Pushmeet Kohli (Head of AI for Science, DeepMind) explained the importance of multidisciplinary collaborations in achieving its success. Protein shape and function are linked, and the ability to predict the shape of a protein would make an important contribution to efforts to understand and treat a range of diseases. Understanding how proteins fold is a long-standing scientific problem that research groups have been working on for many years. This previous research means that researchers already know the physical laws that determine how proteins fold, but even with this knowledge there is a huge number of different ways that a protein could fold before reaching its final configuration. The question for researchers is how to explore all those different configurations and predict the right one. Central to AlphaFold’s success is the combination of pre-existing knowledge about the physics of protein-folding with data-driven approaches. By internalising knowledge about the physical world, AlphaFold can leverage insights form data to predict protein structures more accurately. Combining physical and data-driven insights in this way requires interdisciplinary collaboration.</p>

<p>Such collaboration was on display across the Symposium’s unworkshops:</p>

<ul>
  <li>In a session on sustainability, we heard how AI can be used to support the design of complex building structures with a lower environmental footprint, the creation of novel biomaterials that can be used in sustainable construction, and the development of more effective policy interventions to encourage low-carbon behaviours.</li>
  <li>In a discussion about the interaction between machine learning and the physical world, we heard about applications of AI to analyse climate data, agricultural data, clinical data, and biochemical data, with a focus on the challenges that affect practitioners across a range of disciplines and sectors. Steering AI-enabled analysis using insights from domain experts is central to the success of these projects; such insights help define relevant research questions and interrogate the outputs from AI systems. In the process, AI experts play an important role in guiding expectations about what AI can (and can’t) do, and in creating mechanisms for testing and validating the effectiveness of AI systems.</li>
  <li>An unworkshop on challenges for AI in science and maths explored how different disciplines are leveraging data types to enable research – from string theory to computational biology. While coming from different disciplinary perspectives, researchers often have shared challenges in dealing with highly multidimensional data, and in integrating data from across different scales or data sources.</li>
</ul>

<p>Thank you to Ramit Debnath, Markus Kaiser, Ieva Kazlauskaite, Bianca Dumitrascu, Challenger Mishra, and Sarah Morgan for convening unworkshop discussions, and to all the speakers for their contributions.</p>

<p>These discussions highlight the innovative ways in which researchers across Cambridge – and across research disciplines – are deploying AI to enhance their research. They also demonstrate the importance of interdisciplinary discussions in advancing the use of AI for scientific discovery.</p>

<p>This interdisciplinary approach harks back to the origins of the Cambridge Computer Lab. Under <a href="https://en.wikipedia.org/wiki/Maurice_Wilkes">Maurice Wilkes’s</a> leadership, the Lab set out to accelerate research through the deployment of new computer technologies; essentially to create a computer that could be used by scientists to advance their science. As Ann Copestake (Head of Department of Computer Science and Technology, University of Cambridge) explained at the Symposium, the computer they created was a game-changer: it enabled researchers to run experiments much faster than would otherwise have been possible, contributing to at least four Nobel Prizes awarded to Cambridge at the time. In the process, researchers began to use computing technologies to develop new theoretical approaches, contributing to the development of disciplines like computational linguistics.</p>

<p>There is an opportunity today to develop AI technologies along a similar pathway – from supporting data analysis to driving new types of theory. But the pace of change in AI’s capabilities – and in demand for AI across disciplines – is creating a disconnect between AI researchers and domain researchers. Accelerate is trying to bridge this gap, by building links between those developing and those using AI technologies, and by empowering researchers to deploy AI in their science. This will need new approaches to research and education to accelerate adoption of AI; but fundamentally it will require a renewed wave of interdisciplinary collaboration that creates shared understandings of the potential of AI and fosters new ideas across domains.</p>

<p>This was our first Symposium, and we’d like to thank everyone who contributed to discussions. We hope it marks the start of a continuing discussion across Cambridge about the potential of AI in science, and how the research community can harness this potential. Check out our <a href="https://acceleratescience.github.io/annual-symposium-2021.html">event page</a> for the event video.</p>

<p>Here is a graphic summary of the event:
![Event summary](https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app//Symposium_Summary.png)</p>

<p>Our unworkshop on sustainability:
![Unworkshop summary - sustainability](https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app//Accelerate_UnWk_Sus_Design.png)</p>

<p>Our unworkshop on machine learning and the physical world:
![Unworkshop summary - physical world](https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app//Accelerate_UnWk_Physical_World.png)</p>

<p>Our unworkshop on challenges in science and maths:
![Unworkshop summary - science and maths](https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app//Accelerate_UnWk_Maths_Sci.png)</p>

<p>Our fireside chat about AlphaFold:
![Workshop summary - AlphaFold](https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app//Accelerate_Fireside_Chat_AlphaFold.png)</p>]]></content><author><name>Jess Montgomery, University of Cambridge</name></author><category term="Accelerate-Spark data science residency" /><category term="news" /><summary type="html"><![CDATA[On 19 November, Accelerate brought together researchers from across Cambridge to share perspectives on how AI is supporting their work. This post summarises some of the key points from discussions.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/assets/images/unworkshop_2021_challenges_in_science_and_maths-original.jpg" /><media:content medium="image" url="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/assets/images/unworkshop_2021_challenges_in_science_and_maths-original.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">How can we … better understand the links between mental and physical health with machine learning?</title><link href="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/accelerate-spark%20data%20science%20residency/2021/09/22/Emanuele-Osimo-ML-for-understanding-schizophrenia.html" rel="alternate" type="text/html" title="How can we … better understand the links between mental and physical health with machine learning?" /><published>2021-09-22T17:00:00+01:00</published><updated>2021-09-22T17:00:00+01:00</updated><id>https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/accelerate-spark%20data%20science%20residency/2021/09/22/Emanuele-Osimo-ML-for-understanding-schizophrenia</id><content type="html" xml:base="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/accelerate-spark%20data%20science%20residency/2021/09/22/Emanuele-Osimo-ML-for-understanding-schizophrenia.html"><![CDATA[<p>I’m interested in finding out how mental and physical health are interlinked. <a href="https://www.imperial.ac.uk/people/e.osimo">I study this</a> in serious mental illness, especially in schizophrenia. My long-term aim is understanding how to improve the treatments offered to patients, and help increase their quality of life. In order to do so, we need to disentangle different factors that contribute to a patient’s overall health.</p>

<p>We know that the overall health of people can be affected by:</p>
<ul>
  <li>Life events, including past trauma and stress (for example, migrations, bereavement, infections, etc);</li>
  <li>The person’s lifestyle;</li>
  <li>The person’s socio-economic status, with connected chances and choices;</li>
  <li>Genetic factors that make that individual more susceptible to mental or physical illness;</li>
  <li>The presence of any mental or physical illness;</li>
  <li>The secondary effects of having any illness. These might include side-effects from medications – for example, some medications cause high cholesterol or weight gain – or other secondary effects arising from patients taking less exercise, socialising less, and so on.</li>
</ul>

<p>It isn’t the case that everyone with schizophrenia suffers from poor physical health, but we do see connections between mental illness and conditions like hypertension, diabetes, and the <a href="https://www.nhs.uk/conditions/metabolic-syndrome/">metabolic syndrome</a> (a constellation of connected issues, including usually high blood pressure, high body weight, pre- or fully blown diabetes and other fat-related changes). My work focuses on trying to tease apart some of these different influences on a patient’s health.</p>

<p>There are different ways of studying these relationships. When I first started studying this area, I used imaging; we would carry out <a href="https://www.nhs.uk/conditions/mri-scan/">magnetic resonance scans</a> of people with schizophrenia and healthy controls, and examine how their bodies (particularly I’ve looked at hearts and fat mass) were different from people without the condition. You can find a plain language summary of what we’ve done <a href="https://www.cambridge.org/core/blog/2020/08/19/physically-healthy-people-with-schizophrenia-show-heart-changes-that-increase-the-risk-of-heart-disease/">at this link</a>. The issue with these studies is that it is hard to find a causal relationship from any differences you see – there are usually <a href="https://en.wikipedia.org/wiki/Confounding">confounding factors</a> that make it difficult to be confident in understanding the reasons for different people’s health outcomes. That’s why I’ve also used epidemiological techniques, looking at birth cohort studies where you can compare people’s health trajectories over the life course, excluding data that might be confounding, because so much information is captured about the people in the study. More recently, I’ve been focussing on understanding the genetic basis for disease – this is particularly interesting because it is confounded very little by lifestyle or disease status.</p>

<p>I joined the <a href="https://www.cst.cam.ac.uk/news/free-data-science-training-course-cambridge-researchers">Accelerate-Spark Data Science for Science Residency</a> because I wanted to make progress with a specific project I’m currently working on for my PhD. This is investigating the relationship between different parts of the genome and the likelihood of developing schizophrenia, asking: does a specific part of the genome, or gene, associate with having schizophrenia?</p>

<p>We know from twin-studies that schizophrenia is highly heritable (e.g., some estimates show that around 80% of the risk comes from your genes). Researchers studying the human genome have found many areas of the genome that are linked with the condition through large efforts including thousands of people, called <a href="https://en.wikipedia.org/wiki/Genome-wide_association_study">genome-wide association studies (GWAS)</a>. But schizophrenia is a complex disorder – it is controlled by multiple places (or loci) in the genome, each having a small effect on the development of the condition. When we look at all the common loci we’ve found so far, we can still only account for about 7% of the likelihood of someone developing schizophrenia. Genes themselves make up a relatively small portion of our total genetic material, and one possibility is that the non-coding sections play a more important role in determining whether a person develops schizophrenia than we previously thought.</p>

<p>I’m interested in making better use of the genetic data we have to understand how genetic differences contribute to schizophrenia. To do this, together with my colleagues at the <a href="http://group.genereg.net/">Computational Regulatory Genomics group</a>, among other things, we study the relationship between genes and enhancers. Enhancers are non-coding sequences of the genome that act as regulators of gene expression, or how genes are activated. They can be thought of as switches (or even better, as dimmer switches, as they modulate, rather than switching on and off). If they are switched on “high” in a specific tissue, they will prompt the expression of a particular target gene or set of genes. The relationship between genes and enhancers isn’t simple – an enhancer might affect more than one gene, more than one enhancer might affect a gene, and it isn’t always the case that enhancers and genes are situated close to each other in the genome. To understand their relationship, we need to map the enhancers to the genes they affect: do we know which enhancers might regulate genes associated with schizophrenia?</p>

<p>My colleagues, especially <a href="http://group.genereg.net/group/">Radina Georgieva</a>, had already done lots of work measuring the effect of several genomic features on the relationship between enhancers and genes. This work had identified a number of features that can be used to calculate a probability that an enhancer is controlling a specific gene. In the Accelerate-<a href="https://www.cambridgespark.com">Spark</a> Data Science for Science course, I developed a model that uses these features to predict whether a particular enhancer is influencing the expression of a particular gene.</p>

<p>In machine learning-terms, the techniques I used were pretty simple. I built a simple logistic model, then implemented it in Python. The advantage of using Python is that it comes with a package of other machine learning algorithms – random forests or other classifiers – that I could compare to logistic regression in my work. But even these simple methods allowed me to build a model that can accurately predict enhancer target genes.</p>

<p>Now that I have this analysis – and better understand how different enhancers and genes affect each other – I can move forward to a new phase in my work. With these insights, I’ll be revisiting the Genome-Wide Association Studies that have already been carried out for people with schizophrenia. Those studies gave us signals about which bits of the genome are significant in determining whether someone develops schizophrenia. Many of these signal are not close to genes, but instead they might be tagging enhancers. I hope I can now more accurately map these enhancers to their genes.</p>

<p>One of the most useful things I’ve learned through the Data Science Residency is what machine learning can – and can’t – be used for. It can produce impressive results, but to use it effectively in science you need to have a research question that you can keep in mind when designing your model, and you need to bring to the table strong a priori ideas about what features of your data matter. Internal and external calibration and validation of your model are also really important, and to do this you need to understand both the data science and the science at hand.</p>

<p>In future I hope to be able to apply similar techniques to prediction modelling in other clinical scenarios. The brain is a complicated organ, and as a molecular psychiatry community we need to find new ways of studying it. Techniques like machine learning are becoming important tools in our research toolkit.</p>

<p><strong><em>Emanuele Osimo (September 2021)</em></strong></p>]]></content><author><name>Emanuele Osimo, Chain Florey Clinical Fellow, Imperial College London, and Visiting Researcher, University of Cambridge</name></author><category term="Accelerate-Spark data science residency" /><category term="news" /><summary type="html"><![CDATA[I'm interested in finding out how mental and physical health are interlinked. I study this in serious mental illness, especially in schizophrenia. My long-term aim is understanding how to improve the treatments offered to patients, and help increase their quality of life. In order to do so, we need to disentangle different factors that contribute to a patient’s overall health. Data science and machine learning can help us understand the complex links between mental illness, physical health, and the genetic basis for conditions like schizophrenia.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/%5B%22/assets/uploads/emanueleosimo.jpg%22%5D" /><media:content medium="image" url="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/%5B%22/assets/uploads/emanueleosimo.jpg%22%5D" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">How can we…create next-generation solar technologies using machine learning?</title><link href="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/accelerate-spark%20data%20science%20residency/2021/07/08/JesseAllardice-ML-for-solar-tech.html" rel="alternate" type="text/html" title="How can we…create next-generation solar technologies using machine learning?" /><published>2021-07-08T17:00:00+01:00</published><updated>2021-07-08T17:00:00+01:00</updated><id>https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/accelerate-spark%20data%20science%20residency/2021/07/08/JesseAllardice-ML-for-solar-tech</id><content type="html" xml:base="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/accelerate-spark%20data%20science%20residency/2021/07/08/JesseAllardice-ML-for-solar-tech.html"><![CDATA[<p>As a PhD student in Cambridge, my research focused on developing next-generation technologies for <a href="https://en.wikipedia.org/wiki/Photovoltaic_system">solar photovoltaics</a>, which are vital for sustainable renewable energy. If we’re to make photovoltaics as effective as possible, we need advanced nanomaterials that optimally harvest the Sun’s electromagnetic spectrum. To design these materials, we need better understandings of the quantum dynamics and photo-physics at play.</p>

<p>Working in Physics, I could see lots of cool things being done with machine learning in fields such as <a href="https://deepmind.com/blog/article/AlphaFold-Using-AI-for-scientific-discovery">protein folding</a>, and I was really eager to find out more. The Accelerate-<a href="https://www.cambridgespark.com">Cambridge Spark</a> data science for science residency looked like a great opportunity to learn about machine learning in a condensed format - something I had wanted to do. I was starting the write up of my PhD so I really needed an efficient way to learn this to enable me to both understand machine learning and advance my research. The <a href="https://www.cst.cam.ac.uk/news/july-data-science-residency-applications-open">Accelerate-Spark data science for science residency</a> was perfect for this.</p>

<p>I was working with solar energy materials and the tools I worked with spit out really high multidimensional datasets. Even modest experiments on our setups produces large (&gt;20 GB) and high dimensional (64 * 64* x dimensions) datasets, with information that relates to an array of research-relevant physics. The application of advanced data analysis methods could increase productivity through faster data processing and reveal novel physics hidden in the data.</p>

<p>Senior researchers in the field develop a trained eye to spot these features, but it can be hard for new PhD students. It is important to be able to reduce complexity in the data so you can identify the relevant patterns.</p>

<p>I could see how the application of machine learning could help enable this, so during the Residency I worked on a project converting a legacy matlab tool into Python. This tool converts 256-dimensional time series and reduces it to 2-3 dimensions, meaning you can spot patterns or meaningful results much more quickly. My whole Group now uses this tool, which is similar to <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">Principal Components Analysis</a>, but includes physical constraints (so it reflects the dynamics of the physical systems being studied) and contextualised with domain knowledge.</p>

<p>The key benefit I gained from the Residency is that it accelerated my physics research by rapidly speeding up my data manipulation skills with <a href="https://en.wikipedia.org/wiki/Pandas_(software)">pandas</a> to help open up data and get into it really quickly. It also made more advanced machine learning much less scary to approach.</p>

<p>I wrapped up my PhD a couple of months after the Residency. It was really my experience with Accelerate that encouraged me to focus on creating a new start-up in computer vision and I then moved into a role as a research engineer; something that would not have been possible without the Programme. I was meant to be shooting lasers at silicon but ended up using <a href="https://en.wikipedia.org/wiki/Natural_language_processing">Natural Language Processing</a> – a technique that allows computers to interpret human language – to understand the structure of open banking language for a FinTech company. I also got involved with Cambridge Spark as a Tutor which helped me continue my learning.</p>

<p>Ultimately, all this experience helped me to convey my interest to secure a position at Apple’s first <a href="https://machinelearning.apple.com/updates/introducing-aiml-residency-program">AI Residency Programme</a>. I can definitely point to the Accelerate course and Cambridge Spark as key factors in getting the position.</p>

<p><strong><em>Jesse Allardice (July 2021)</em></strong></p>]]></content><author><name>Jesse Allardice, (formerly) Department of Physics, University of Cambridge</name></author><category term="Accelerate-Spark data science residency" /><category term="news" /><summary type="html"><![CDATA[Solar photovoltaic technologies are vital for sustainable renewable energy. If we’re to make photovoltaics as effective as possible, we need advanced nanomaterials that optimally harvest the Sun’s electromagnetic spectrum. To design these materials, we need better understandings of the quantum dynamics and photo-physics at play. Machine learning can help develop these understandings by analysing high-dimensional datasets to reveal novel physics.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/%5B%22/assets/uploads/jesseallardice.jpg%22%5D" /><media:content medium="image" url="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/%5B%22/assets/uploads/jesseallardice.jpg%22%5D" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">How can we…use data science to inform fundamental physics?</title><link href="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/accelerate-spark%20data%20science%20residency/2021/07/08/Andreas-Schachner-ML-for-string-theory.html" rel="alternate" type="text/html" title="How can we…use data science to inform fundamental physics?" /><published>2021-07-08T17:00:00+01:00</published><updated>2021-07-08T17:00:00+01:00</updated><id>https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/accelerate-spark%20data%20science%20residency/2021/07/08/Andreas-Schachner-ML-for-string-theory</id><content type="html" xml:base="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/accelerate-spark%20data%20science%20residency/2021/07/08/Andreas-Schachner-ML-for-string-theory.html"><![CDATA[<p>The past century has seen the most spectacular discoveries and theoretical developments in fundamental physics. Studying how the curvature of spacetime encodes the force of gravitation has advanced our understanding of <a href="https://en.wikipedia.org/wiki/General_relativity">general relativity</a>, while <a href="https://en.wikipedia.org/wiki/Quantum_mechanics">quantum mechanics</a> allowed us to describe nature at the sub-atomic level. On top of that, <a href="https://en.wikipedia.org/wiki/Quantum_field_theory">quantum field theory</a> emerged as the idea that our world is traversed by fields vibrating in a certain harmony, together materialising the world around us. The language of field theory has proven incredibly useful in deciphering nature to an astonishing level of precision.</p>

<p>In spite of these successes, many questions of fundamental physics remain unanswered. In my PhD, I am focusing on <a href="https://en.wikipedia.org/wiki/String_theory">string theory</a> and its potential implications on our understanding of nature. In basic terms, string theory proposes that the world around us is composed of vibrating strings, rather than individual particles. Drawing from the ideas of quantum field theory, mentioned above, string theory allows us to unify an infinite number of fields in an abstract, higher-dimensional space. When we try to connect string theory to our observed four-dimensional Universe (one time and three space directions), the theory becomes inherently entangled with compact geometries (e.g. circles, spheres and generalisations thereof) in the context of so-called string compactifications. These compactifications are the bridge between the high number of dimensions that string theory predicts and the four dimensions we can observe, and so sit at the heart of the physics that shapes the world around us. To study these theories and interpret the physics they produce, we already use a heavy machinery of mathematical tools.</p>

<p>However, there are a huge number of choices involved in the analysis of string theory, giving rise to a seemingly endless number of predictions about the interactions involved - the so-called <a href="https://en.wikipedia.org/wiki/String_theory_landscape">string landscape</a>. Analysing the full landscape would require us to generate and process datasets with up to 10^500 elements by exploring different solutions of the equations of motion. Ultimately, at least one of them should describe our real would as we know it, but no guiding principle has emerged yet. In practical terms, a complete scan is computationally infeasible. Even if it were feasible, there are computational complexities that make the analysis highly challenging.</p>

<p>Nonetheless, there are strategies we can use to analyse the landscape more effectively. In my PhD, for example, I’ve been able to make progress by identifying which of the aforementioned solutions can be discarded because they are physically irrelevant. Complementing these efforts, we can develop data-driven tools to facilitate our search for viable solutions of string theory. The advent of ‘Big Data’ provides a golden opportunity to shine new light on such datasets and more generally on some of the open questions in mathematical physics. It is this interplay of a triad of fields - mathematics, physics and data science - that has fascinated me for a long time.</p>

<p>The “Accelerate-Spark - Data for Science Residency Programme“ has given me a chance to further develop my data processing and handling skills, which are prerequisites for attacking the above tasks. Over the course of six weeks, I have benefited especially from the tutorials on data preprocessing utilising the Python package Pandas. Here, I acquired new skills in quickly manipulating and filtering data for specific tasks which has sped up significantly the computer-based aspects of my research projects. Similarly, the lectures and assignments on data visualisation using e.g. Bookeh have substantially improved the way I present my data to collaborators and at conferences. In the long run, these competencies are imperative when disseminating my research. Lastly, the interdisciplinary outline of the workshop has led to stimulating discussions among the participants. I believe that this has been a great event for early-career researchers to build a network across various disciplines.</p>

<p>Currently, I am working on a follow-up of one of my earlier papers on applying <a href="https://en.wikipedia.org/wiki/Genetic_algorithm">genetic algorithms</a> – algorithms that solve optimisation problems using a strategy that is inspired by evolutionary biology - to the string landscape. In our latest project, we provide a code for computing general set-ups using auto-differentiation via JAX which is a Python package “for high-performance machine learning research“. Further, we contrast applications of genetic algorithms and <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a> to traversing the humongous space of available solutions. This allows us to investigate correlations among the various physical solutions which can inform physicists about where to look for interesting phenomena. While general results from these investigations are still pending, the progress of this project was heavily influenced by the techniques I learnt over the course of the Residency programme. Most importantly, it provided the very foundation on which I was able to expand my expertise and to develop efficient new applications of AI to mathematical physics.</p>

<p>Overall, the programme has had a significant impact on my research, especially on the way I approach new projects involving data. In the future, I am continuing to promote the interdisciplinary scope of my research by highlighting the beautiful symbiosis of mathematical rigorousness, physical intuition and computer scientific methods.</p>

<p><strong><em>Andreas Schachner (August 2021)</em></strong></p>]]></content><author><name>Andreas Schachner, Department of Applied Mathematics and Theoretical Physics, University of Cambridge</name></author><category term="Accelerate-Spark data science residency" /><category term="news" /><summary type="html"><![CDATA[The past century has seen the most spectacular discoveries and theoretical developments in fundamental physics, but despite this success many questions of fundamental physics remain unanswered. In my PhD, I am focusing on string theory and its implications for our understanding of nature.To study string theories and interpret the physics it produces, we already use a heavy machinery of mathematical tools. Data science and machine learning offer a new route to interrogating how the predictions arising from string theories map onto the world around us.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/%5B%22/assets/uploads/andreasschachner.JPG%22%5D" /><media:content medium="image" url="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/%5B%22/assets/uploads/andreasschachner.JPG%22%5D" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">How can we…expedite data curation for understanding the cell biology of parasites?</title><link href="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/accelerate-spark%20data%20science%20residency/2021/06/24/NicolaMoloney-ML-for-parasitology.html" rel="alternate" type="text/html" title="How can we…expedite data curation for understanding the cell biology of parasites?" /><published>2021-06-24T15:00:00+01:00</published><updated>2021-06-24T15:00:00+01:00</updated><id>https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/accelerate-spark%20data%20science%20residency/2021/06/24/NicolaMoloney-ML-for-parasitology</id><content type="html" xml:base="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/accelerate-spark%20data%20science%20residency/2021/06/24/NicolaMoloney-ML-for-parasitology.html"><![CDATA[<p><em>In this new blog series, members of the Cambridge AI for science community tell us about how participation in the Accelerate-Spark data science for science residency has contributed to their research. In this post, <a href="https://www.bioc.cam.ac.uk/directory/ms-nicola-moloney">Nicola Moloney from the Department of Biochemistry</a> tells us about her work.</em></p>

<p>My research involves spatially mapping the <a href="https://en.wikipedia.org/wiki/Proteome">proteomes</a> of parasites that cause African <a href="https://en.wikipedia.org/wiki/Trypanosomiasis">trypanosomiasis</a>, a disease which substantially reduces the productivity of livestock animals in sub-Saharan Africa. Understanding the proteome – the set of proteins that a cell produces – is crucial in understanding how a cell works, and (in the case of a disease-causing organism) developing effective treatments. One important way to understand the proteome is to study where proteins are found within a cell. Protein function is often tightly linked with localisation and, consequently, where a protein is found can provide information on its role within the cell.</p>

<p>Spatial proteomics can use machine learning methods with quantitative proteomic data to determine where proteins are localised within a cell. To do this, researchers use purpose-built supervised machine learning methods on multidimensional experimental data, to classify which proteins are found in which parts of a cell (known as subcellular compartments). Such classification requires training data, in the form of proteins with a literature-supported localisation within a cell (i.e. data about proteins with characterised functions and localisations).</p>

<p>My main motivation for attending the Accelerate-<a href="https://cambridgespark.com">Cambridge Spark</a> data science for science residency was to learn ways to expedite the curation of this training data via programmatic access to scientific literature, in addition to learning new ways to explore large datasets.</p>

<p>During <a href="https://www.cst.cam.ac.uk/news/july-data-science-residency-applications-open">the course</a> I worked on a project to mine scientific literature in an automated way for information on localisations for individual proteins. This was achieved by accessing online literature databases programmatically via their <a href="https://en.wikipedia.org/wiki/API">APIs</a>. I had no previous experience with using an API before and learned how to from the course lectures and with the help of my project mentor throughout. After the course, I was then equipped to develop this project further into a fully working version. This enabled me to build a database that allows me to efficiently curate a training dataset for use in my research. Other researchers in the domain will also be able to use this tool.</p>

<p>The course also trained me in how to generate interactive visualisations that could be shared with others easily. This is especially helpful as it facilitates the sharing of processed data in informative visualisations without requiring others to run code. Altogether, this course provided me with (i) an overview of other tools in data science that have application in my research, (ii) an ability to implement some of these tools, and (iii) a stronger basis from which I can learn new methods. Importantly, the experience instilled me with a confidence to further explore data science for use in my work. As a result, I more readily attempt to use new tools I learn about and have done so successfully.</p>

<p>Generally, I’ve found that the data science methods I learned on the course enable me to better understand my data by interrogating it with a toolbox of methods, more exhaustively analyse my data by expediting processes, proficiently communicate it with others through visualisations, and better organise my data through improved data management practices. I increasingly use data science in my research and continue to actively develop my skills herein. I plan to continue this tract in future roles.</p>

<p><strong><em>Nicola Moloney (June 2021)</em></strong></p>]]></content><author><name>Nicola Moloney, Department of Biochemistry, University of Cambridge</name></author><category term="Accelerate-Spark data science residency" /><category term="news" /><summary type="html"><![CDATA[Understanding the proteome – the set of proteins that a cell produces – is crucial in understanding how a cell works, and (in the case of a disease-causing organism) developing effective treatments. One important way to understand the proteome is to study where proteins are found within a cell - known as spatial proteomics. Spatial proteomics can use machine learning methods with quantitative proteomic data to determine where proteins are localised within a cell.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/%5B%22/assets/uploads/nicolamoloney.jpg%22%5D" /><media:content medium="image" url="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/%5B%22/assets/uploads/nicolamoloney.jpg%22%5D" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">How can we…understand the crafts of ancient communities using machine learning?</title><link href="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/accelerate-spark%20data%20science%20residency/2021/06/10/EmBauztye-ML-for-archeology.html" rel="alternate" type="text/html" title="How can we…understand the crafts of ancient communities using machine learning?" /><published>2021-06-10T17:49:00+01:00</published><updated>2021-06-10T17:49:00+01:00</updated><id>https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/accelerate-spark%20data%20science%20residency/2021/06/10/EmBauztye-ML-for-archeology</id><content type="html" xml:base="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/accelerate-spark%20data%20science%20residency/2021/06/10/EmBauztye-ML-for-archeology.html"><![CDATA[<p><em>In this new blog series, members of the Cambridge AI for science community tell us about how their participation in the Accelerate-Spark data science for science residency has contributed to their research. In this first post, <a href="https://www.arch.cam.ac.uk/staff/dr-ema-bauzyte">Ema Bauzyte from the Department of Archeology</a> tells us about her work.</em></p>

<p>The composition of metals found at archeological sites can tell us a lot about the communities that lived in an area – their creativity, their approach to innovation, and their social identity. In my research, I analyse metals found at archeological sites in Cyprus, using chemical composition analysis, CT imaging and optical microscopy to investigate what metals were used by whom, and to understand how craftspeople in these communities worked.</p>

<p>The field of archeology is becoming more interested in machine learning. In my research, I work with chemical data with lots of variables. To get insights from this data, I need to be able to explore these variables across lots of different dimensions. I applied to the <a href="https://acceleratescience.github.io/spark-course-summary.html">Accelerate-Spark data science for science residency</a> as an opportunity to learn how to efficiently process datasets in automated ways while reducing errors.</p>

<p>Machine learning also seemed like a great way to help keep up with the literature. Last year for example, there was <a href="https://doi.org/10.1016/j.palaeo.2020.109849">a major article</a> on strontium <a href="https://en.wikipedia.org/wiki/Isotope_analysis">isotopes</a> used for <a href="https://en.wikipedia.org/wiki/Provenance">provenancing</a> studies. Analysing the amount of these isotopes present at archeological sites is an important way of assessing the provenance of organic material, but the baselines for these studies usually have to be established through painstaking and expensive empirical analysis of local plants and animals. However, modeling has increasingly been used to predict isotopic ratios. By pooling the available data together and using <a href="https://en.wikipedia.org/wiki/Random_forest">random-forest regression</a>, this paper predicted bioavailable strontium isotope ratios on a global scale. We can then use this information to trace origins of animals and people in the archaeological record. Other applications I have found inspiring relate to the automated identification of structures in images, such as use of Regions-based <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional Neural Networks</a> to identify archaeological features (like barrows or fields) in aerial images.</p>

<p>While I had actually completed my PhD a while ago, during the course I decided to return to my thesis and applied the <a href="https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding">t-sne</a> algorithm to my research. This already proved incredibly helpful in identifying clusters in my data. Using <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">Principal Components Analysis</a> and t-sne helped to unlock insights into clusters and relationships between analysed objects that were not possible to see as a human. This approach has helped to answer questions relating to the connectivity of different areas and visualise exactly which sites are related.</p>

<p>The Accelerate Programme and working with <a href="https://cambridgespark.com/">Cambridge Spark</a> gave me the confidence and curiosity to learn how to use different algorithms and solve problems with machine learning. Cleaning data with code has become part of my day-to-day work. I use these skills all the time – I have moved away from Excel as a result! I am conducting a lot of analysis using techniques like t-sne or hierarchical clustering. I am also now able to engage a lot more with the literature on machine learning and archeology and see how conclusions can be applied in this research.</p>

<p>I can see these methods will change how landscape studies are conducted in archeology. Archeology traditionally looked at small datasets on one site. With machine learning, it is possible to mine legacy data and see more macro-scale analysis enabling more global studies over time. I also believe that the application of machine learning to archeology can shift the perception of the domain being purely Humanities to more interdisciplinary with ways of working with data which can lead to more innovation and could help make a stronger case for funding.</p>

<p><strong><em>Ema Bauzyte (June 2021)</em></strong></p>]]></content><author><name>Ema Bauzyte, Department of Archeology, University of Cambridge</name></author><category term="Accelerate-Spark data science residency" /><category term="news" /><summary type="html"><![CDATA[The composition of metals found at archeological sites can tell us a lot about the communities that lived in an area. In my research, I analyse metals found at archeological sites in Cyprus to investigate what metals were used by whom, and to understand how craftspeople in these communities worked.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/%5B%22/assets/uploads/emabauzyte.jpg%22%5D" /><media:content medium="image" url="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/%5B%22/assets/uploads/emabauzyte.jpg%22%5D" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Welcome to Accelerate Science</title><link href="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/machine%20learning/2021/04/15/welcome-to-accelerate.html" rel="alternate" type="text/html" title="Welcome to Accelerate Science" /><published>2021-04-15T11:20:05+01:00</published><updated>2021-04-15T11:20:05+01:00</updated><id>https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/machine%20learning/2021/04/15/welcome-to-accelerate</id><content type="html" xml:base="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/machine%20learning/2021/04/15/welcome-to-accelerate.html"><![CDATA[<p>The Department for Computer Science and Technology was set up in the 1930s, when it was known as the Mathematical Laboratory. At that time ‘computer’ had a different meaning – a computer was a person employed to do numerical calculations by hand – and there was growing demand for a shrinking pool of people able to perform this work. Recent advances in mechanical systems looked promising, but these automated ‘computers’ weren’t considered suitable for the complex problems that were of interest to scientists at the University. In 1936, University leaders agreed that, if the University was to be at the forefront of the use of the new computing revolution, researchers would require wider access to these mechanical systems, as well as more sophisticated computing machinery. The Mathematical Laboratory was created with this mission.</p>

<p>We’re now in a new phase of the development of computing, with rapid advances in machine learning attracting attention from across scientific domains. But we see some of the same issues emerging. While researchers across disciplines hope to make use of machine learning, they need access to skills and tools to use machine learning in their research. In parallel, researchers in machine learning need to develop more sophisticated methods to tackle complex, ‘real world’ problems.</p>

<p>It is with these challenges in mind that the Department for Computer Science and Technology has started the Accelerate Programme for Scientific Discovery. This new Programme seeks to advance the frontiers of science through the use of machine learning, by supporting researchers to develop skills to use machine learning in their research and by creating new collaborations.</p>

<p><strong>Machine learning for science at Cambridge</strong></p>

<p>In pursuing this mission, the Programme is building on a legacy of successful work at the interface of machine learning and science. Researchers at Cambridge are using machine learning as part of efforts to improve healthcare outcomes, to monitor environmental change, and to develop new materials. Outside the University, impressive advances in the use of machine learning to tackle major scientific questions – how do proteins fold? how is climate change affecting the Earth? – have also attracted widespread attention.</p>

<p>These high-profile successes can act as beacons, inspiring researchers to pursue ambitious projects at the interface of machine learning and the sciences. Realising these ambitions will require interventions that move cutting edge tools and techniques from the hands of the world’s leading AI companies into the hands of the scientists. Our aim is to develop the portfolio of tools available to these scientists and the skills base to use those tools, empowering researchers to drive forward their discoveries.</p>

<p>Our ambition is that the Accelerate Programme can build the bridges we need to achieve these outcomes. Too often, disciplinary boundaries contribute to a situation where those researchers working with machine learning in a scientific domain are isolated from a wider machine learning community, lacking access to the expertise they need to avoid reinventing the wheel or chasing phantoms. If we can create links between the machine learning community and the wider scientific community – building on the work already going on across Cambridge at the interface of machine learning and the sciences – then we will find opportunities and connections that can deliver a step change in the use of machine learning for science.</p>

<p><strong>The Accelerate Programme for Scientific Discovery</strong></p>

<p>With this aim, Accelerate is developing three areas of activity:</p>

<ul>
  <li>Research: we’re developing a research agenda that applies cutting edge machine learning methods to scientific challenges, with four Accelerate Research fellows developing research projects that seek to advance both the use of machine learning in science and the science of machine learning.</li>
  <li>Education: building on the teaching activities already delivered through University courses, we’re creating learning opportunities for Cambridge researchers to develop skills in machine learning and to create machine learning tools that can help tackle real-world challenges.</li>
  <li>Engagement: we hope that Accelerate will build a community of researchers working across the University at the interface on machine learning and the sciences, helping to share best practice and new methods, and support each other in advancing their research. Over the coming years, we’ll be running a variety of events and activities in support of this.</li>
</ul>

<p>This website will be the hub for material from the Programme, hosting research, resources, and highlighting opportunities to engage with our activities. We’ll be posting further details as they become available. In the meantime, to keep in touch, please visit our ‘Get Involved’ page.</p>]]></content><author><name>Neil Lawrence and Jess Montgomery</name></author><category term="Machine Learning" /><category term="news" /><summary type="html"><![CDATA[Welcome to the Accelerate Programme! This new initiative will be advancing research at the interface of machine learning and the sciences.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/%5B%22/assets/uploads/APSci_social-asset_white.jpg%22%5D" /><media:content medium="image" url="https://roaring-rugelach-b8c77e.netlify.app/https://roaring-rugelach-b8c77e.netlify.app/%5B%22/assets/uploads/APSci_social-asset_white.jpg%22%5D" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>